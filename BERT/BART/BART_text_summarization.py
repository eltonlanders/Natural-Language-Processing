#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Created on Thu May 27 19:53:50 2021

@author: elton
"""
#!pip install transformers==4.5.0.
#!pip install torch==1.8.0.
from transformers import BartTokenizer, BartForConditionalGeneration 
import torch
import transformers



# Downloading and loading the model and tokenizer
model = BartForConditionalGeneration.from_pretrained('facebook/bart-large-cnn')
tokenizer = BartTokenizer.from_pretrained('facebook/bart-large-cnn')

# The test text to summarize
text = """Machine learning (ML) is the study of computer algorithms that improve automatically through experience.\
It is seen as a subset of artificial intelligence. Machine learning algorithms build a mathematical model based on sample data, \
known as training data, in order to make predictions or decisions without being explicitly programmed to do so.\
Machine learning algorithms are used in a wide variety of applications, such as email filtering and computer vision, \
where it is difficult or infeasible to develop conventional algorithms to perform the needed tasks."""

inputs = tokenizer([text], max_length=1024, return_tensors='pt')

# Getting the summary ids which are the ids of the tokens generated by the model
summary_ids = model.generate(inputs['input_ids'], num_beams=4, 
                             max_length=100, early_stopping=True)

# Decode the summary id and getting the corresponding token (word)
summary = ([tokenizer.decode(i, skip_special_tokens=True, 
                   clean_up_tokenization_spaces=False) for i in summary_ids])

print(summary)



# Test paragraph
text = "At its simplest form, artificial intelligence is a field, which combines computer science and robust datasets, \
to enable problem-solving. It also encompasses sub-fields of machine learning and deep learning, \
which are frequently mentioned in conjunction with artificial intelligence. \
These disciplines are comprised of AI algorithms which seek to create expert systems which make predictions or classifications based on input data."

inputs = tokenizer([text], max_length=1024, return_tensors='pt')

summary_ids = model.generate(inputs['input_ids'], num_beams=4, max_length=100, early_stopping=True)

summary = ([tokenizer.decode(i, skip_special_tokens=True, clean_up_tokenization_spaces=False) for i in summary_ids])

print(summary)



# Test paragraph
text = "Modern science is typically divided into three major branches that consist of the natural sciences (e.g., biology, chemistry, and physics), \
which study nature in the broadest sense; the social sciences (e.g., economics, psychology, and sociology), \
which study individuals and societies; and the formal sciences (e.g., logic, mathematics, and theoretical computer science), \
which deal with symbols governed by rules. There is disagreement, however, on whether the formal sciences actually constitute \
a science as they do not rely on empirical evidence. Disciplines that use existing scientific knowledge for practical purposes, \
such as engineering and medicine, are described as applied sciences."

inputs = tokenizer([text], max_length=1024, return_tensors='pt')

summary_ids = model.generate(inputs['input_ids'], num_beams=4, max_length=100, early_stopping=True)

summary = ([tokenizer.decode(i, skip_special_tokens=True, clean_up_tokenization_spaces=False) for i in summary_ids])

print(summary)
